{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installing modules\n",
        "These line should be run only for colab"
      ],
      "metadata": {
        "id": "xxJbw7pgg8fX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%%bash\n",
        "pip install --upgrade tensorflow\n",
        "pip install scann\n",
        "pip install -q tensorflow-recommenders\n",
        "pip install -q tensorflow_hub\n",
        "#these line should be run only on colab"
      ],
      "metadata": {
        "id": "duh1-wzF17kp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing modules\n",
        "Import of:\n",
        "\n",
        "\n",
        "*   Tensorflow\n",
        "*   Tensorflow Recommenders: contains the ScaNN layer we are going to use\n",
        "*   Tensorflow Hub: contains the embedding model we are going to pass to the ScaNN layer\n",
        "*   os: for path managment\n"
      ],
      "metadata": {
        "id": "mXO5odWBhGE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_recommenders as tfrs\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "import os \n",
        "import shutil"
      ],
      "metadata": {
        "id": "UKOsQWfphp7r"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating the index\n",
        "\n",
        "The following function creates the index given a dataset of embeddings.\n"
      ],
      "metadata": {
        "id": "nwpHM1lWh9vb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_index(dataset, embedding_model = None):\n",
        "  \"\"\"\n",
        "  :param dataset: a tensorflow dataset with the embedded version of the space we want to query in\n",
        "  :param embedding_model: a tensorflow model(loaded with tf hub or thorugh keras load_model function) that embeds strings into multidimensional vectors. The embedder should be the same as the one used to create :param dataset:\n",
        "  :return: the index model \n",
        "  \"\"\"\n",
        "\n",
        "  index = tfrs.layers.factorized_top_k.ScaNN() #this is the model without the \n",
        "\n",
        "  test_value = tf.constant(list(dataset.as_numpy_iterator())[0])\n",
        "  if embedding_model is not None:\n",
        "    index = tfrs.layers.factorized_top_k.ScaNN(query_model = embedding_model)\n",
        "    test_value = tf.constant([''])\n",
        "\n",
        "  index.index_from_dataset(dataset.batch(512))\n",
        "\n",
        "  _ = index(test_value)\n",
        "\n",
        "  return index"
      ],
      "metadata": {
        "id": "JSti_UGniC6l"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# General function to create and save the index in SaveModel format\n",
        "\n",
        "The following function generates the servable version of the model."
      ],
      "metadata": {
        "id": "oBQnqGQrjP9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_save(dataset:tf.Tensor or tf.data.Dataset, save_path:str, version:int = 1, embedding_model:tf.keras.Model = None, zip:bool = False):\n",
        "  \"\"\"\n",
        "  :param dataset: a tensorflow dataset with the embedded version of the space we want to query in\n",
        "  :param save_path: a path, as string, that saves the model \n",
        "  :param version: creates a subfolder to the \n",
        "  :param embedding_model: a tensorflow model(loaded with tf hub or thorugh keras load_model function) that embeds strings into multidimensional vectors. The embedder should be the same as the one used to create :param dataset:\n",
        "  :param zip: a boolean, if it is true, creates a zip of the model saved\n",
        "  :return: the index model \n",
        "  \"\"\"\n",
        "\n",
        "  index = create_index(dataset, embedding_model) #creating the index\n",
        "\n",
        "  path = os.path.join(save_path, str(version)) #adding the version subfolder\n",
        "\n",
        "  index.save(filepath = path) #saving the index\n",
        "  \n",
        "  if zip:\n",
        "    shutil.make_archive(base_name = save_path, format = 'zip', base_dir = save_path) #zipping if zip is True\n",
        "  \n",
        "  return index"
      ],
      "metadata": {
        "id": "VwihpDCvjJdz"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create and save specific\n",
        "\n",
        "Creates and saves the model on the job_desc dataset with keyword extraction and using the Universal Sentence Encoder model\n",
        "\n",
        "- get_repo:"
      ],
      "metadata": {
        "id": "nEm95gsHZBjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_repo() -> None:\n",
        "  \"\"\"\n",
        "  clones the repository atuomatically\n",
        "  \"\"\"\n",
        "\n",
        "  try:\n",
        "    os.system('git clone https://github.com/UniversalDot/tensorflow')\n",
        "  except:\n",
        "    print('it was not possible to get the dataset')\n",
        "    return\n",
        "  finally:\n",
        "    print('dataset downloaded')"
      ],
      "metadata": {
        "id": "AnOWgNIOaTWT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset() -> tf.Tensor:\n",
        "  \"\"\"\n",
        "  loads the dataset in a format readable from the create_save function\n",
        "  \"\"\"\n",
        "  df = tf.data.Dataset.load('/content/tensorflow/dataset/key_embeddings')\n",
        "  df = tf.reshape(df.get_single_element(), (-1, 512))\n",
        "  df = tf.data.Dataset.from_tensor_slices(df)\n",
        "  return df"
      ],
      "metadata": {
        "id": "BnIWZoU_gwNE"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def jobdesc_create_save(save_path:str, version:int = 1, zip:bool = False):\n",
        "  \"\"\"\n",
        "  Create and saves the index model with the dataset jobdesc with keywords extracted and embedded with the Universal Sentence Encoder\n",
        "  \n",
        "  :param save_path: a path, as string, that saves the model \n",
        "  :param version: creates a subfolder to the \n",
        "  :param zip: a boolean, if it is true, creates a zip of the model saved\n",
        "  :return: the index model \n",
        "  \"\"\"\n",
        "  get_repo() #loading the github repo\n",
        "  df = get_dataset() #loading the embedding dataset from the github repop\n",
        "  print('Got repo and dataset')\n",
        "  USE_encoder = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4') #loading the encoder\n",
        "  print('Got encoder\\nstarting to train the model...')\n",
        "\n",
        "  model = create_save(df, save_path, version, USE_encoder, zip) #creating and saving the model\n",
        "  print('Model trained')\n",
        "  return model "
      ],
      "metadata": {
        "id": "zQvET3WaZAtv"
      },
      "execution_count": 25,
      "outputs": []
    }
  ]
}